# directive: Process to execute
# - 0: train network
# - 1: run evaluation
# - 2: load results/copy to local for viewing
# - 3: MEEP simulations
# - 4: data preprocessing and formatting for model
# - 5: mode encoding
# deployment: Deployment mode
# - 0: local
# - 1: kubernetes

directive: 1
deployment: 1   

#--------------------------------
#       General Params
#--------------------------------

# General Parameters
# - seed: random seed


seed: [True, 1337]

#--------------------------------
#       Network Params
#--------------------------------

model:
    # - arch: Network Architecture
    # *** Learning a mapping from design parameters to DFT fields ***
        # - 0: Dual MLPs - separate MLPs for real and imaginary
        # - 1: CVNN - Complex-valued MLP
    # *** Learning wavefront propagation ***
        # - 2: LSTM
        # - 3: ConvLSTM
        # - 4: AE-LSTM - LSTM with linear autoencoder
        # - 5: AE-ConvLSTM - ConvLSTM with convolutional autoencoder
        # - 6: mode-LSTM - LSTM operating on a deterministic dim reduction of the fields
            # - SVD, random projection, gauss, fourier
        # - 7: diffusion - img2video diffuser model
    # *** Learning a reconstrutible latent representation of the fields ***
        # - 8: Autoencoder - Used in conjunction with arch 4, 5
    # *** Learning a mapping from DFT fields to design parameters ***
        # - 9: Inverse - simple swap of x and y or Tandem (if objective_function set to resim)
        # - 10: Neural Adjoint 
        # - 11: WaveInverseConvMLP
    # - model_id: model identifier / name

    arch:  1
    model_id: "forward_na_bad"

    # General Model Parameters

    optimizer: 'ADAM'
    learning_rate: 1.e-4
    lr_scheduler: 'ReduceLROnPlateau'
    #lr_scheduler: 'CosineAnnealingLR'
    load_checkpoint: False
    objective_function: 'mse'
    #objective_function: "resim"    
    #objective_function: "resim_bdy" 
    #forward_ckpt_path : "/develop/results/meep_meep/cvnn/model_forward_na/model.ckpt"
    #forward_config_path: "/develop/results/meep_meep/cvnn/model_forward_na/params.yaml"
    na_iters: 1000
    K: 10000
    radii_bounds: [0.0750, 0.2500] # check units! these are in nm
    conv_out_channels: 16
    source: 'fields' # 'fields' or 'projections'
    num_projections: 10 # Number of projections to use as input
    # multi-criteria loss
    mcl_params:
        alpha: 1
        beta: 1
        gamma: 1
        delta: 1

    # MLP Parameters
    # - ***separate MLPs for real and imaginary parts, or a single CVNN***
    # - layers: Hidden layer neuron counts, len(layers) = number of hidden layers
    # - activation: Activation function for hidden layers
    # - mlp_strategy: 0: full, 1: patch-wise 2: distributed subset; 3: all_slices
    # - num_design_conf: number of design configurations (usually 3x3: 9)
    # - patch_size: patch height/width for patch wise or distributed subset

    mlp_real:
        layers: [64, 256, 32]
        activation: 'relu'

    mlp_imag:
        layers: [64, 256, 32]
        activation: 'relu'

    cvnn:
        layers: [64, 128] # forward
        #layers: [512, 64] # inverse
        #conv_layers: [[16, 5, 5], [32, 5, 5]]
        #layers: [512, 64]
        #layers: [256, 32]
        #layers: [512, 64]
        activation: 'complexrelu'
        use_resnet: false
        #resnet_variant: resnet50 # options are 18 and 50

    mlp_strategy: 0
    patch_size: 3
    num_design_conf: 9 # radii
    #num_design_conf: 27556 # inverse: 166*166*2
    #num_design_conf: 2 # ConvMLP
    interpolate_fields: False

    # LSTM Parameters
    # - num_layers: number of lstm layers (i.e., stacked networks)
    # - i_dims: number of input dimensions for lstm
    # - h_dims: number of hidden dimensions for lstm

    lstm:
        num_layers: 1
        i_dims: 55112 # this is (r/i * 166 * 166)
        h_dims: 256

    # Mode-LSTM Parameters - LSTM but data has already been encoded
    # - i_dims: input dimensionality - depends on the encoding method
    # ----> svd: spatial * k (optimal) * 2
    # ----> random: any perfect square
    # - spatial: spatial size of the input
    # - w0: beam waist parameter (laguerre-gaussian)
    # - p_max: radial index max (laguerre-gaussian)
    # - l_max: azimuthal index max (laguerre-gaussian)
    # - method: encoding types ('svd' or 'random' or 'gauss' or 'fourier')

    modelstm:
        num_layers: 1
        i_dims: 6 
        h_dims: 64
        spatial: 166
        w0: 1.0
        p_max: 39
        l_max: 20
        seed: 1337
        method: 'svd'


    # ConvLSTM Parameters
    # - in_channels: number of input channels for conv
    # - kernel_size: size of the conv kernel
    # - padding: padding for the conv layer
    # - use_ae: utilize autoencoder
    # - pretrained_ae: use pretrained autoencoder
    # - latent_dim: latent dimension for autoencoder
    # - encoder_channels: encoder channel progression
    # - decoder_channels: decoder channel progression

    convlstm:
        num_layers: 1
        in_channels: 2
        out_channels: 64
        kernel_size: 5
        padding: 2
        spatial: 166

    # Autoencoder Parameters
    # - encoder_channels: encoder channel progression
    # - decoder_channels: decoder channel progression
    # - pretrained: use pretrained autoencoder
    # - freeze_weights: whether to freeze weights
    # - spatial: spatial size of the input
    # - method: layer types ('linear' or 'conv')

    autoencoder:
        encoder_channels: [2, 32, 64] # each step halves
        decoder_channels: [64, 32, 2] # each step doubles
        latent_dim: 512
        pretrained: True
        freeze_weights: False
        use_decoder: False
        spatial: 166
        method: 'linear'

    # General Time Series Parameters
    # - seq_len: number of time steps
    # - io_mode: 'one_to_many' or 'many_to_many'
    # - spacing_mode: 'sequential' or 'distributed'
    # - autoreg: autoregressive mode or teacher forcing - M2M only

    seq_len: 15
    io_mode: 'one_to_many'
    spacing_mode: 'sequential'
    autoreg: True

#--------------------------------
#       Training Params
#--------------------------------
trainer:
    batch_size: 8
    num_epochs: 100 # maximum

    accelerator: 'gpu' 
    gpu_config: [True, [0]]
    valid_rate: 1
    load_checkpoint: False


    # - include_testing: True/Falsee - whether to test right after training
    # - cross_validation: True/False - whether to perform cross-validation
    # ---> if False, then a 5-fold 80/20 split is used

    include_testing: False
    cross_validation: False

    # early stopping settings
    patience: 50
    min_delta: 0.000001

#--------------------------------
#       All paths
#--------------------------------
paths:
    root: '/develop/'
    data: 'data/'
    train: 'train/'
    valid: 'valid/'
    results: 'results/meep_meep/'
    volumes: 'nfe-data/volumes'
    library: 'code/near_field_emulator/utils/neighbors_library_allrandom.pkl'
    pretrained_ae: 'meep_meep/autoencoder/model_ae-v1/'

#--------------------------------
#       Physical Params
#--------------------------------
physics:
    #Metasurface simulation
    Nx_metaAtom: 3
    Ny_metaAtom: 3
    Lx_metaAtom: 680.e-9
    Ly_metaAtom: 680.e-9

    n_fusedSilica: 1.44
    n_PDMS: 1.4
    n_amorphousSilica: 3.48

    h_pillar: 102.e-9
    thickness_pml: 780.e-9
    thickness_fusedSilica: 780.e-9
    thickness_PDMS: 1560.e-9

    #General
    wavelength: 1550.e-9

    #Fourier propagation
    distance: 10.e-6
    Nxp: 176
    Nyp: 176
    Lxp: 2.04e-6
    Lyp: 2.04e-6
    adaptive: True

#--------------------------------
#       Datamodule Params
#--------------------------------
data:
    # - n_cpus: number of cpus
    # - n_folds: number of folds for cross val
    # - buffer: True/False - whether to use buffer dataset or old U-Net data (no buffer)
    # - subset: False/int - False to use all data, (int) N to use subset of N samples
    # - all_slices: True/False - whether to load all slices (not just the last one) 
    # - wavelength: wavelength to use for preprocessing
    # ---> [2.881, 1.65, 1.55, 1.3, or 1.06]
    # - eval_wavelength: wavelength to use for evaluation
    n_cpus: 5
    n_folds: 3
    buffer: True
    subset: False
    all_slices: True
    wavelength: 1.55
    eval_wavelength: 1.55
    source: 'fields' # 'fields' or 'projections'

#--------------------------------
#       Kube Params
#--------------------------------
kube:
    namespace : gpn-mizzou-muem
    image : docker.io/kovaleskilab/ml_basic:v4
    job_files : kube/kube_jobs  # this is a local directory
    pvc_volumes : dft-volumes # use `kubectl get pvc` to see list of pvcs
    pvc_preprocessed : nfe-data 
    pvc_results : training-results
    pvc_projections: braket_results

    data_job:
        num_cpus : 32
        num_parallel_ops : 2
        num_mem_lim : 200Gi 
        num_mem_req : 200Gi
        kill_tag : data-job

        paths:
            # local / repo path where meta-atom radii are stored

            # interactive pod directories
            data:
                volumes: /develop/data/nfe-data/volumes  # points to folder containing reduced volumes in pvc called dft-volumes
                preprocessed_data: /develop/data/preprocessed_data # points to folder containing data after it has been preprocessed in pvc called preprocessed-data 
            timing: /develop/data/preprocessed_data/timing 

            # local path where template is located
            template: kube/templates/data_job.txt

    train_job :
        num_cpus : 16
        num_mem_lim : 100Gi
        num_mem_req : 100Gi
        num_gpus : 1
        kill_tags : [mlp,lstm,convlstm]
    
        paths :
            data :
                train : /develop/data/preprocessed_data/train
                valid : /develop/data/preprocessed_data/valid
            results :
                # interactive pod directories
                model_results : /develop/results
                model_checkpoints : /develop/results/checkpoints
                analysis : /develop/results/analysis
            logs : /develop/results/checkpoints/current_logs
            # local path where template is located
            template : kube/templates/train_job.txt

    load_results_job :
        num_mem_req : 64Gi
        num_mem_lim : 128Gi
        paths :
            template : templates/load_results_job.txt
            params: configs/params.yaml

    evaluation_job :
        paths:
            template : kube/templates/evaluation_job.txt
